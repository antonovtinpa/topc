Така започваме с дефиниция на KV store, това е nonrelational база данни, чиито освновни елементи са ключовете и стойностите. Всеки ключ е уникален и отговаря на една стойност. Тази семпла база ни позволява да държим, четем и пишем данни от памет, което я прави в пъти по-бърза от конвенционалните и persistent алтернативи.

Точно и в такива use cases бихме  използвали KV store пред SQL база, за бърз обмен на данни, най-често на често използвани данни или на кратко бихме го използвали за cache. 

Какво искаме от един КВ сторе:
- Да е бърз
- Да има висок процент availability
- Да може да се справя с голям брой заявки
- Да може да се справя с голям размер данни
- Да ни позволява да скалираме

Първи опит да създадем КВ сторе би изглеждал по следният начин - Пускаме специален сървър, в който сме декларирали един hashmap (hashtable) и започваме да записваме и да четем стойности. Бързо разбираме, че нито можем да се справям с голям брой заявки, нито да се справяме с голям размер данни, нито можем да скалираме лесно, общо взето отговаряме само на изискването да сме бързи и то само понякога.

Започваме да дистрибутираме за да започнем да поправяме пропуските си. Първо ни трябва стратегия, за това се съобразяваме с CAP теоремата (Consistency, Availability, Partition Tolerance). Тя ни казва, че ние можем да гарантираме за нашият КВ сторе само две от тези три неща, като този факт теоритично ни дава три стратегии CA, AP & CP. На практика имаме само две - AP & CP - CA, тоест Consistency & Availability е невъзможна стратегия в реалният свят, защото евентуалният partition e неизбежен, тоест не можем да сме и консистентни и на разположение 100% от времето. Разглеждаме останалите стратегии:
- CP - Consistency & Partition Tolerance за сметка на Availability. Когато се появи partition между една инстанция на нашият сторе и останалите, всяка write & последователна read операция води до неконсистентни данни, освен ако не заключим всички write операциите докато не преустановим връзката.
- AP - Availability & Partition Tolerance за сметка на Consistency. При установен partition, продължаваме работа както обикновено и приемаме възможността за неконсистентни данни, при условие, че имаме механизми, които синхронизират всички инстанции при преустановяване на връзката.
Според нашите нужди избираме едно от двете, ако сме банка бихме избрали CP, ако сме социална медия AP.

Започваме да разглеждаме различните компоненти, които са нужни на нашата система.

Дистрибутирането на данните ни е неизбежно, просто сме сигурни, че физическият ресурс на една инстанция ще се изчерпа, за това завъртаме Н на брой инстанции, в които да рапределяме данните си. Връщаме се на миналата глава от която ще вземем идеята за consistent hashing и ще имплементираме в нашата дистрибутирана система, това ни позволява да скалираме автоматично и да се справяме с премахването на сървъри.

Следваща нужда, която трябва да покрием е това да имаме бекъпи на данните ни, това се случва, чрез репликация. Благодарение отново на consistent hashing можем да използваме hashing ring-a ни и вместо, когато избираме сървър за данните ни да избираме следващият сървър по посока часовниковата стрелка, избираме следващите Н сървъри, като Н е по наша преценка (Добре е те да са в различни дата центрове за да се защитим от физически проблеми).


---
Вече сме установили дистрибутирането и репликирането на нашите данни и съответно имаме "отговорници" за отделни групи данни. За да установим и консистентност на нашите данни  трябва да създадем кворум за писане и четене на данни. Кворум е колектив от decisionmakers, тоест представлява минималният брой реплики, които трябва да потвръдят, че една операцият е окей. Имаме Н на брой реплики, кворум за писане от В реплики и кворум за четене от Р реплики. Решенията се взимат на база нашата стратегия за консистентност, тя може да е силна, слаба и евентуална. При силната резултата от read операция връщаме задължително последната ъпдейтната стойност. При слабата при read операция нямаме задължителен достъп до последната ъпдейтната стойност. При евентуалната всички ъпдейти се препращат и след време тоест евентуално всички реплики са консистентни.

При неконсистентности между данните ние трябва да имаме подготвени механизми, които да ни помагат да се справяме с тях. Два са основните похвати, които можем да използваме. Единият е versioning на данните - на кратко всеки ъпдейт на определени данни се приема като отделни данни с инкрементирана версия. Това обаче не е достатъчно за да се справим с колизия, единственото, което ни позволява е да видим, че такава се е случила. В такъв случай използваме векторни часовници, това са вектори, които съдържат историята на единица данни, те съдържат всички направени промени от различните инстанции и техните версии. Те са последователни и е лесно да засечем дали една версия на данните е по-нова от друга или дали две версии са се променили независимо една от друга.

Ако една версия доминира друга (всички стойности в нейния вектор са по-големи или равни на тези в другата версия), то тя е по-новата и валидна версия. Ако обаче две версии имат несъвместими векторни часовници, тоест нито едната не доминира другата, това означава, че имаме конфликт. За разрешаването на конфликти можем да приложим автоматично сливане – комбинираме различните версии или други стратегии.

---
Последното нещо, което трябва да направим е да предвидим случаите, в които определена инстация fail-не или не е на разположение. За да знаем дали една инстанция наистина не е на разположение не можем да разчитаме само на друга такава да обяви, че не е на разположение, трябва да имаме походящ механизъм или протокол, който да установява проблемите. Имплементираме така нареченият Gossip протокол, където всяка инстанция държи списък с ид-та на Н на брой други иснтанции и последният път, в който са получили сигнал от тях, така нареченият пулс. Всеки път когато един ноде получи сигнал той го предава на всички инстанции в списъка си. Когато никой не е получил сигнал за "живот" от една определена инстанция тя се флагва като failed или out of order. В такива случаи трябва да имаме готовност да се справим с този проблем. Първото нещо, което трябва да направим е да се погрижим да не блокираме системата, това може да се случи ако този отказ на инстанцията ни доведе до недостиг на acknowledgements в кворума ни, тогава ние използваме "sloppy quorum" и използваме първите R/W работещи инстанции, като делегираме отговорността на неработещият сървър на друг, като когато оправим проблема всички промени по временният "отговорник" се прехвърлят обратно. Превантивни мерки срещу постоянен failure на съврър е проток за консистентно синхронизиране на репликите, това се случва, чрез специален прокол, който създава Merkle дърво за всяка реплика и чрез него той сравнява къде има проблеми с консистентността.

Голям зор 😫
