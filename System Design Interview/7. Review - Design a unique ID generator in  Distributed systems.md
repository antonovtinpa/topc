Така трябва да трябва да изградим дистрибутиран ID генератор, който да отговаря на следните изисвания:
- Всяко ИД трябва да е уникално
- ИД-тата трябва да бъдат сортируеми
- ИД-тата трябва да се инкрементират с времето, не е задължително да е с разлика от 1, но ИД-тата от началото на деня трябва да са по-малки от тези в края
- Генераторът трябва да може да генерира по 10хил. в секунда
Представяме няколко подхода, които можем да предприемем:
1. Multi-master replication - Използваме генератор, който просто autoincrement-ва ИД-тата, но вместо стандартният аутоинкремент от 1, инкрементираме с К, където К е броят на database сървърите, които имаме. Не е много походящ поход, поради факта, че трудно се скалира, не дава гаранция, че ИД-тата нарастват между различните сървъри и трудно бихме се адаптирали при добавяне и премахване на сървър.
2. UUID - Unique uniform identifier е 128-битово ид, което се състои от букви и числа. Вече нарушихме две от изискваниятя, така че знаем, че и това не е походящият подход, но си заслужава да го разгледаме. Почти невъзможно е да се получат колизии между UUID-та, което го прави много лесен начин да идентифицираме елементи, понеже можем да имаме уникални ид-та между реплики, които даже не трябва да се синхоринизират, но не ни дава сортируемост, нито нарастващи ид-та, нито пък отговаря на изискванията ни за размер.
3. Ticket Server - Това е поход, при който имаме единствен централизиран Ticket Server/Generator, който ни предоставя аутоинкремент функционалност чрез елементарна таблица и множество реплики, които са постигнати, чрез някаква шардинг стратегия, според нуждите ни. Всеки инсерт минава през този сървър и се предава към определена реплика. Доста семпло и интуитивно, но имаме SPF, можем да вземем различни мерки за справяне с това. Не е лош вариант, но ние ще се фокусираме върху последният.
4. Twitter Snowflake - Този подход е дело на една от най-големите социални мрежи в света - Twitter. Те не използват класически функционалности като autoincrement или UUID. Вместо това те изцяло custom-изират ИД-тата, като ги създават на база следната структура:
	1. 1 бит в началото, който се нарича sign bit, по default e 0 и е заделен за бъдещо ползване, когато ще може да се определи знак на ИД-то.
	2. 41 бита за timestamp, това е времето в милисекунди от даден epoch, било то стандартният или custom такъв, в Twitter използват epoch oт 2010-та. 41 бита позволяват timestamp-ове за около 70 години, след това ни трябва нова стратегия или нов epoch.
	3. 5 бита за id-то на дата центъра, в който се намира инстанцията на генератора. Позволява за 32 дата центъра.
	4. 5 бита за id-то на самта инстанция, която генерира ИД-то. Позволява за 32 генератора/сървъра/инстанции за всеки датацентър.
	5. 12 бита за sequence number - Тук вече се използва аутоинкремент. Това ще е номера на ИД-то генерирано от един сърврър в един дата център, като този номер се ресетва на всяка милисекунда. Тоест позволява генерирането на 4096 Ид-та за всеки сървър за всеки датацентър.
5. Неща, които трябва да се имат в предвид при Snowflake подхода.
	- Трабвя да имаме синхронизирани часовници между отделните дата центрове и съответно генератори, в противен случай timestamp-овете няма да работят правилно, от гледна точка на сортируемост и опасности от колизии. Най-често решението е NTP.
	- Можем да настроим структурата на ИД-то, например ако нямаме нужда от 4000 ИД-та в милисекунда можем да намалим sequence number-a и да увеличим timestamp-овете.