Така имаме известен проблем, познат като "Design Top K". Трябва да имплементираме autocomplete feature, още познато като search-as-you-type или incremental search. Целта на този продукт е да дава предположения на потребителите на база популярност по време на тяхното търсене.

Изискванията за системата са следните:
- Приемаме търсения само на английски език и правим преположението, че всички търсения ще бъдат с малки букви
- На база търсенето на потребителя ние предлагаме 5-те най-популярни подобни търсения.
- Нашата система трябва да поддържа 10 милион активни потребители всеки ден (10М DAU).
- От MVP-то изключваме всякакви спелчекъри, аутокорект и поддръжка на други езици
- Системата трябва да предоставя предположения бързо и да имаме добро ниво на availability.
BOE Анализ:
- Предполагаме, че всеки потребител прави то 10 запитвания всеки ден, всяко запитване се състои от 4 думи от 5 символа, като всеки символ е заема стандартно 1 байт.
- За всеки нов символ от търсенето трябва да направим заявка, тоест $QPS = (10M * 10 * 4 * 5 ) / 24 / 3600 = 24 000$. Това означава, че PQPS e 48 000.
- Ако предположим, че от всички търсения всеки ден 20% са нови търсения, значи на ден ние ще консумираме $10M * 10 * 20 * 0.2 = 0.4 GB$.

Можем да изградим една наивна система много бързо и без много размисъл, това и прави аторът в High Level Design частта. Реално погледнато ни трябва две части:
1. Data gathering service - За всяка заявка от потребител записваме търсенето и актуализираме честотата на запитване, тоест ако например потребител потръси "topcoding" в нашата търсачка, ние просто ще потърсим това търсене в нашата база и ще инкрементираме колоната, която пази честотата или ще направим нов запис с честота 1, ако не съществува.
2. Query Service - За всяко запитваме директно търсим в базата други запитвания, които започват по същият начин, подреждаме ги по честота на търсене и връщаме първите 5.
Нашата система е готова да поддържа 3-ма потребители :D. Разбира се трябва да се потрудим малко повече за да изградим скалируема система, която да работи ефективно и да поддържа 10DAU.

Първата ни стъпка би била да използваме подходяща структура от данни, която ще ни помогне да правим бързи предположения. Запознава ме се с Prefix Tree структурата или така нареченият Trie. Префикс дървото е дървовидна сртуктура, която е създадена с цел оптимална работа със стрингове. Корена на дървото е празен стрингм всеки Ноуд представляа определена дума или начало на дума и всеки ноуд има 26 деца, дете за всяка буква от азбуката. Така по продължението на един path акумулираме символи и сформираме думи. Например "" -> "t" -> "to" -> "top" би бил един path. За да можем да се възползваме от префикс дървото и да отговорим на изискването за сортируемост трябва да добавим и frequency counter към Ноуда.
Към този момент за да получим предположения за дадено търсене, бихме направили следното нещо:
1. Трябва да намерим prefix-a
2. Трябва да траверснем цялото събдърво и да намерим ноудовете с реални думи
3. Трябва да сортираме намерените ноудове по честота
Тоест имаме О(P), където Р е дължината на префикса + О(C), където С е броят деца в събдървото + О(C * logC), тук С ще е малко по-малко стойност, защото не всички деца са реални думи, но горе долу ще получим разултат в time complexity О(P) + О(C) + О(C * logC),
което не е зле, но със сигурност е неефективно. За това просто когато изграждаме дървото можем да пазим предположенията за всеки префикс, например:
```json
{
	"top": [["topcoding", 10], ["topcoding2", 14]]
}
```
Така изразхождаме ресурс само да стигнем до префикса.

Нека обновим няшият data gathering service, до сега актуализирахме честотите на търсенията в релационната ни база данни при всяко търсене, това е много трудоемък и бавен процес, който не можем да си позволим. Установеното решение от други продукти е вместо това да се използват агрегирани данни от логове и аналитики. Тоест събирамe така наречената raw data при всяко търсене и на определен период от време (според зависи от use case-a, в нашият случай веднъж седмично) започваме процес на обновяване. Той се състои в агрегиране на данните във формат, който можем да използваме, да кажем, че ни трябва търсенето и честотата, след това тези данни се предават на worker-и, по един или друг начин, например чрез message queue-та, които от своя страна изграждат префикс дървото, има два начина за изграждане:
1. Създават изцяло ново дърво и го заменят със старото
2. Актуализар всеки ноуд по отделно. Това не е предпочитаният вариант понеже за всяка промяна в ноуд ние трябва да попагираме промените нагоре, което ни връща в първа база.
След като изградим дървото ние го запазваме в нерелационна база данни за persistence и съответно в кеш за бързо четене.

Query service-a ще бъде обновен по следният начин. Клиента изпраща заявка към сървъра за определено търсене, минава през load balancer, стига до web server, той проверява кеша за търсенето, ако е там връща отговор ако не прави заявка към базата запазва отговора в кеша и го връща.

Тази система е многократно по-лесна за скалиране. Ако искаме да скалираме базата делим сървъра на две или три и пропорционално делим азбуката 13 букви за единият 13 за другият. Можем да стигнем до 26 сървъра за всяка буква, а дори да започнем да скалираме по втори символ.

В wrap up-a можем да си говорим за поддръжка на други езици, чрез поддържка на unicode символи в префикс дървото. Поддръждка предположения в различни региони и държави, чрез създаване на множество дървета за всеки регион и използване на CDN-и за бързо четене. Може да се говори и за real-time актуализация на търсенията, което е доста по-сложна система и трябва да се възползваме от data streaming услуги.