Имаме задача да направи дизайн на rate limiter, първо трябва да се знае какво е РЛ и за какво е полезен. РЛ е част от архутектурата, която контролира трафика в контекста на уеб приложение контролира броят заявки, които се правят към сървъра.

Когато ни дадат тази задача първата стъпка според фреймуорка от миналта глава е да разберем какви са параметрите и изискванията. Започваме с това къде точно ще правим ограничението, на клиента или на сървъра, честно казано аз не съм чувал за рейт лимит от към клиента, най-вероятно защото не е много популчрно, самият автор казва, че няма как да имамe reliable рейт лимитинг на клиента, така че ще го имплементираме откъм сървъра. Втора стъпка, РЛ ще бъде интегриран в апито (апликацията) или ще бъде отделен сървиз, има плюсове и минуси за двата избора, авторът се спира на отделен сървиз, през който ще се минава преди да се пусне рекуеста към апито, ще служи като middleware (ако правим сравнително малка апликацията, без големи планове за скейлинг би било окей и да е част от монолит). Друго, което трябва да уточним е на база на какво ще лимитираме, на база имейл, ид, ип или други (аз лично съм правил рейт лимит само на база app info - имейл или ид). След като сме уточнили какви са изискванията авторът обобщата, правим РЛ като мидълуеър, целта ни е да е light weight, бърз, да се справя добре с грешки и след като е отделен сървиз да не бъде зависим от други компоненти в системата.

Втора стъпа е high level архитектура. Общо взето използваме изводите, до които сме стигнали от първа стъпка и започваме с избирането на алгоритъм за РЛ. Авторът дава пример за 5 алгоритма:
- Token bucket - Имаме едно място (бъкет), където държим определен брой токени (образно казано), на определено време презареждаме определен брой токени, при всяка заявка декрементираме броя токени с 1. Ако нямаме токени в бъкета рекуеста дропва. Тоест имаме един цикъл от декрементиране и инкрементиране на токени. Тука трудното е да се определят стойностите за големина на бъкетите и рефилинг процеса през колко време и по колко токена да се инкрементират.
- Leaking bucket - При този алгоритъм имаме едно фифо кю (first in first out) от определен размер и от което се взимат заявки на определено време, когато стинем макс размер и получим заявка тя дропва. Тук също най-трудното е да се установят добри правила тоест размер на опашката и интервал за декю на заявки.
- Fixed window counter - Тук разделяме timeline-а на определени времеви прозорци (еднакви) тоест можем да го разделим на 1,2,3,5 секунди, минута или каквото ни трябва на нас и в този интервал имаме каунтър от определен размер. За даден интервал от време можем да приемем Н на брой заявки, останалите дропват. Тук проблема се появява когато съберем повече заявки на границата между интервалите тоест да кажем искаме да обработваме 5 заявки на минута (минута, защото е по-лесно за описване) и влязат 5 между секунда 30 и секунда 59, на секунда 60 ние сме отворили още 5 места и в такъв случай то 00:30 до 01:30 ние можем да обработим 10 заявки, което не нашата цел.
- Sliding window log - Този алгоритъм решава проблема на предишният като пази лог с timestamp-ове и когато влезе нова заявка проверява колко таймстампа има в определеният от нас интервал, тоест за интервал за интервал от 1 минута ако влезе заявка в 01:57 ние ще проверим логовете от 00:58 до сега, ако те са или надвишават определена бройка ние ще дропнем заявката, така избягваме проблема с границите. Тук проблемът е че изразхождаме много памет.
- Sliding window count - Този алгоритъм е хибрид между двата предишни, честно казано не го разбрах напълно, имаме плаващ прозорец тоест не ни интересуват точни моменти на таймлайна, а Н на брой единици преди сегашният момент и вместо да пазим таймстампове пазим приблизителна стойност на броя заявки чрез някакво процентово калкулиране....
Който и алгоритъм да използваме ще използваме Редис за имплементацията, понеже ни продоставя ин мемори сторидж, тоест бърз ретривъл, плюс вградени функционалности като инкремент.

Примерен флоу на системата би било - клиент прави рекуест, той минава през рейт лимитъра, прави се проверка на база правилата (правилата се записват на персистен диск, полват се от редиса на определен интервал от време) ако клиента е в рамките на лимита рекуеста се раутва към апито, изпълняваме съответната стъпка от алгоритма за да запишем, че сме приели рекуест, ако не е трябва да кажем на клиента, че е лимитиран. Това се клучва най-често чрез статус код 429 и къстъм хедъри.

Споменават се за проблеми, когато РЛ ни е в дистрибутирана система. Има проблеми с рейс кондишъни, когато приемеме заявки в почти едно и също време и резултата от първата не е готов, когато започнем да обработваме втората, можем да се справим с това чрез определена дата структура в Редис. Другият проблем е синхронизацията между отделни инстанции на РЛ, но просто можем да използваме централизиран сторидж.

От към перформънс можем винаги да се възползваме от различни геолокации за по-бърза връзка между различни клиенти.

Трябва да установим система за мониторинг за да проверяваме дали правилата и алгоритъмът ни са оптимални.

Нищо не помня от wrap up-a XD освен че могат да се направи рейт лимитър на друго ниво от оси модела освен на application layer-a, да кажем на база IP (network layer), не знам тука вече си говоря глупости.
